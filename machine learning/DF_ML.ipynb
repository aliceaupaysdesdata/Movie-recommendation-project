{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 62)) while a minimum of 1 is required by NearestNeighbors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[100], line 83\u001b[0m\n",
      "\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similar_movies\n",
      "\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Exemple\u001b[39;00m\n",
      "\u001b[1;32m---> 83\u001b[0m selection2 \u001b[38;5;241m=\u001b[39m recommandation2(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtt0099487\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m     84\u001b[0m selection2\n",
      "\n",
      "Cell \u001b[1;32mIn[100], line 40\u001b[0m, in \u001b[0;36mrecommandation2\u001b[1;34m(tconst)\u001b[0m\n",
      "\u001b[0;32m     37\u001b[0m caract_film \u001b[38;5;241m=\u001b[39m df_test_encoded[df_test_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtconst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m tconst]\n",
      "\u001b[0;32m     38\u001b[0m caract_film \u001b[38;5;241m=\u001b[39m caract_film[caracteristiques]\n",
      "\u001b[1;32m---> 40\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkneighbors(caract_film)\n",
      "\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Sélection des indices trouvés\u001b[39;00m\n",
      "\u001b[0;32m     43\u001b[0m colonnes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnconst\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n",
      "\u001b[0;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n",
      "\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n",
      "\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n",
      "\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n",
      "\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n",
      "\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n",
      "\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n",
      "\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n",
      "\u001b[0;32m   1076\u001b[0m         )\n",
      "\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 62)) while a minimum of 1 is required by NearestNeighbors."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def recommandation2(tconst):\n",
    "\n",
    "    index = df_test.index\n",
    "    df_test_num = df_test.select_dtypes('number')\n",
    "    df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    SN = MinMaxScaler()\n",
    "    df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "    # Encoding categorical columns, including 'nconst'\n",
    "    df_test_cat_encoded = df_test_cat.copy()\n",
    "    label_encoders = {}\n",
    "    for col in df_test_cat_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_test_cat_encoded[col] = le.fit_transform(df_test_cat_encoded[col].fillna('unknown'))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    df_test_encoded = pd.concat([df_test_num_SN, df_test_cat_encoded], axis=1)\n",
    "\n",
    "    # On crée une liste des colonnes à utiliser pour le modèle\n",
    "    caracteristiques = df_test_encoded.columns.drop(['tconst', 'title', 'tmdb_popularity', \n",
    "                                                     'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', \n",
    "                                                     'tmdb_US', 'tmdb_FR', 'tmdb_GB'])\n",
    "\n",
    "    # Séparation bons/mauvais films\n",
    "    bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "    mauvais_films = df_test_encoded[df_test_encoded['notes'] < 0.7]\n",
    "\n",
    "    # Création du modèle\n",
    "    model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "    model.fit(bons_films[caracteristiques])\n",
    "\n",
    "    # Définition des caractéristiques du film sélectionné\n",
    "    caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst]\n",
    "    caract_film = caract_film[caracteristiques]\n",
    "\n",
    "    distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "    # Sélection des indices trouvés\n",
    "    colonnes = ['tconst', 'genres', 'overview', 'nconst']\n",
    "    selection = bons_films.iloc[indices[0]][colonnes]\n",
    "    df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "    # Définition des poids pour chaque colonne\n",
    "    colonnes_poids = {\n",
    "        'tconst': 1,\n",
    "        'genres': 1,\n",
    "        'overview': 1,\n",
    "        'nconst': 30  # Increased weight\n",
    "    }\n",
    "\n",
    "    # Pondération des colonnes\n",
    "    df_tfidf = df_selection.copy()\n",
    "    df_tfidf['texte'] = df_selection.apply(\n",
    "        lambda ligne: ' '.join(\n",
    "            (str(ligne[col]) + ' ') * poids for col, poids in colonnes_poids.items()\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calcul TF-IDF\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "    df_tfidf_matrix = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "    # Similarité cosine\n",
    "    similarite = cosine_similarity(df_tfidf_matrix)\n",
    "\n",
    "    # Classement des résultats\n",
    "    similarity_scores = list(enumerate(similarite[0]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "    return similar_movies\n",
    "\n",
    "# Exemple\n",
    "selection2 = recommandation2('tt0099487')\n",
    "selection2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_episodes = \"../exploration/BIG_DF_ML.ipynb\"\n",
    "\n",
    "db01 = pd.read_csv(\"../gitignore/title_basics_traite.csv\")\n",
    "db02 = pd.read_csv(\"../gitignore/title_ratings_final.tsv\", sep=\"\\t\")\n",
    "db03 = pd.read_csv(\"../gitignore/title.akas_final.tsv\", sep=\"\\t\")\n",
    "db04 = pd.read_csv(\"../gitignore/tmdb_ml_final.csv\")\n",
    "db05 = pd.read_csv(\"../gitignore/data_bechdel.csv\")\n",
    "db07 = pd.read_csv(\"../gitignore/name.basics.tsv\", sep=\"\\t\") \n",
    "db08 = pd.read_csv(\"../gitignore/title.crew.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbmerge_1 = pd.merge(db01, db02, right_on='title_ratings_tconst', left_on='tconst', how='left') #Title Basics + Title Ratings\n",
    "dbmerge_2 = pd.merge(dbmerge_1, db03, left_on='tconst', right_on='titleId', how='left') # + Title Akas\n",
    "dbmerge_3 = pd.merge(dbmerge_2, db04, left_on='tconst', right_on='tmdb_imdb_id', how='left') # + TMDB Full\n",
    "dbmerge_4 = pd.merge(dbmerge_3, db05, left_on='tconst', right_on='imdbid', how='left') # + Bechdel\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db08, left_on='tconst', right_on='tconst', how='left') # + Title Crew\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db07, left_on='directors', right_on='nconst', how='left') # + Name Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbmerge_4.to_csv(\"../gitignore/BIG_DF_ML.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie\n",
       "True    688341\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbmerge_4['movie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML = dbmerge_4.drop(columns=[\n",
    "    'titleType',\n",
    "    'genres', \n",
    "    'decade', \n",
    "    'Adult',\n",
    "    'Short',\n",
    "    'movie',\n",
    "    'tmdb_Comedy',\n",
    "    'tmdb_Adventure',\n",
    "    'tmdb_Drama',\n",
    "    'tmdb_Crime',\n",
    "    'tmdb_Action',\n",
    "    'tmdb_Documentary',\n",
    "    'tmdb_Animation',\n",
    "    'tmdb_Mystery',\n",
    "    'tmdb_Horror',\n",
    "    'tmdb_Western',\n",
    "    'tmdb_Science Fiction',\n",
    "    'tmdb_Thriller',\n",
    "    'tmdb_Romance',\n",
    "    'tmdb_Fantasy',\n",
    "    'tmdb_Family',\n",
    "    'tmdb_History',\n",
    "    'tmdb_Music',\n",
    "    'tmdb_War', \n",
    "    'ordering',\n",
    "    'region',\n",
    "    'language',\n",
    "    'types',\n",
    "    'attributes',\n",
    "    'isOriginalTitle',\n",
    "    'birthYear',\n",
    "    'deathYear',\n",
    "    'primaryProfession',\n",
    "    'knownForTitles',\n",
    "    'directors',\n",
    "    'writers'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_ratings_tconst</th>\n",
       "      <th>title_ratings_averageRating</th>\n",
       "      <th>tmdb_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357199 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_ratings_tconst  title_ratings_averageRating  tmdb_vote_average\n",
       "9                       NaN                          NaN                NaN\n",
       "10                      NaN                          NaN                NaN\n",
       "11                      NaN                          NaN                NaN\n",
       "12                      NaN                          NaN                NaN\n",
       "13                      NaN                          NaN                NaN\n",
       "...                     ...                          ...                ...\n",
       "688329                  NaN                          NaN                NaN\n",
       "688335                  NaN                          NaN                NaN\n",
       "688336                  NaN                          NaN                NaN\n",
       "688337                  NaN                          NaN                NaN\n",
       "688340                  NaN                          NaN                NaN\n",
       "\n",
       "[357199 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIG_DF_ML.loc[(dbmerge_4['title_ratings_averageRating'].isnull())&(dbmerge_4['tmdb_vote_average'].isnull()), ['title_ratings_tconst', 'title_ratings_averageRating', 'tmdb_vote_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML3 = BIG_DF_ML.dropna(subset=['title_ratings_averageRating','tmdb_vote_average'],how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2696331554.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def moyenne_ponderee(ligne):\n",
    "\n",
    "    # Si 'title_ratings_averageRating' est NaN, on ne prend que 'tmdb_vote_average', et vice versa\n",
    "\n",
    "    if pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        return ligne['tmdb_vote_average']  # Si title_ratings_averageRating est vide, prendre tmdb_vote_average\n",
    "\n",
    "    elif pd.isna(ligne['tmdb_vote_average']) and not pd.isna(ligne['title_ratings_averageRating']):\n",
    "        return ligne['title_ratings_averageRating']  # Si tmdb_vote_average est vide, prendre title_ratings_averageRating\n",
    "\n",
    "    elif not pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        # Si les deux colonnes ont des valeurs, calculer la moyenne pondérée\n",
    "        return (ligne['title_ratings_averageRating'] * ligne['title_ratings_numVotes'] + ligne['tmdb_vote_average'] * ligne['tmdb_vote_count']) / (ligne['title_ratings_numVotes'] + ligne['tmdb_vote_count'])  # Moyenne simple, à ajuster si besoin !\n",
    "    else:\n",
    "        return np.nan  # Si les deux sont NaN, retourner NaN\n",
    "\n",
    "\n",
    "BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML4 = BIG_DF_ML3.drop(['title_ratings_averageRating','tmdb_vote_average','title_ratings_tconst','titleId','tmdb_imdb_id','imdbid', 'primaryName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startyear(ligne):\n",
    "\n",
    "    # Si 'start year' est 0, il prend la valeur 'tmbd release date'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['startYear'] == 0)&(BIG_DF_ML4['tmdb_release_date'] != 0), 'startYear'] = BIG_DF_ML4['tmdb_release_date']\n",
    "\n",
    "startyear(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_date(ligne):\n",
    "\n",
    "    # Si 'tmdn release date' est 0, il prend la valeur 'start year'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_release_date'] == 0)&(BIG_DF_ML4['startYear'] != 0), 'tmdb_release_date'] = BIG_DF_ML4['startYear']\n",
    "\n",
    "release_date(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_date(ligne):\n",
    "\n",
    "    # Si 'tmdn release date' est 0, il prend la valeur 'start year'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_release_date'].isna())&(BIG_DF_ML4['startYear'] != 0), 'tmdb_release_date'] = BIG_DF_ML4['startYear']\n",
    "\n",
    "release_date(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'runtimeMinutes' est 0, il prend la valeur 'tmdb_runtime'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['runtimeMinutes'] == 0)&(BIG_DF_ML4['tmdb_runtime'] != 0), 'runtimeMinutes'] = BIG_DF_ML4['tmdb_runtime']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'tmdb_runtime' est 0, il prend la valeur 'runtimeMinutes'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_runtime'] == 0)&(BIG_DF_ML4['runtimeMinutes'] != 0), 'tmdb_runtime'] = BIG_DF_ML4['runtimeMinutes']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "import numpy as np\n",
    "BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "BIG_DF_ML4[BIG_DF_ML4['runtimeMinutes']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML4.drop(columns =['tmdb_runtime','tmdb_release_date','tmdb_original_title','tmdb_title','tmdb_vote_count','tmdb_TV Movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['runtimeMinutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['startYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\61637864.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Pour notre ML, on remplace toutes les valeurs nulles des pays de production par False \n",
    "Remplacer = [\n",
    "    'tmdb_US', 'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "    'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE', 'tmdb_SU',\n",
    "    'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR', 'tmdb_RU', 'tmdb_DK',\n",
    "    'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR', 'tmdb_PL', 'tmdb_CH', 'tmdb_XC',\n",
    "    'tmdb_FI', 'tmdb_NO', 'tmdb_IR', 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'\n",
    "]\n",
    "BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['rating'] = BIG_DF_ML5['rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['title_ratings_numVotes'] = BIG_DF_ML5['title_ratings_numVotes'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['tmdb_popularity'] = BIG_DF_ML5['tmdb_popularity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['nconst'] = BIG_DF_ML5['nconst'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']] = BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = \"../machine learning/DF_ML.csv.gz\"\n",
    "BIG_DF_ML5.to_csv(export, sep=\",\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = BIG_DF_ML5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de ML avec cible sur les notes > 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 301086 entries, 0 to 688339\n",
      "Data columns (total 69 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   tconst                  301086 non-null  object \n",
      " 1   startYear               301086 non-null  float64\n",
      " 2   runtimeMinutes          301086 non-null  float64\n",
      " 3   Action                  301086 non-null  bool   \n",
      " 4   Adventure               301086 non-null  bool   \n",
      " 5   Animation               301086 non-null  bool   \n",
      " 6   Biography               301086 non-null  bool   \n",
      " 7   Comedy                  301086 non-null  bool   \n",
      " 8   Crime                   301086 non-null  bool   \n",
      " 9   Documentary             301086 non-null  bool   \n",
      " 10  Drama                   301086 non-null  bool   \n",
      " 11  Family                  301086 non-null  bool   \n",
      " 12  Fantasy                 301086 non-null  bool   \n",
      " 13  Game-Show               301086 non-null  bool   \n",
      " 14  History                 301086 non-null  bool   \n",
      " 15  Horror                  301086 non-null  bool   \n",
      " 16  Music                   301086 non-null  bool   \n",
      " 17  Musical                 301086 non-null  bool   \n",
      " 18  Mystery                 301086 non-null  bool   \n",
      " 19  News                    301086 non-null  bool   \n",
      " 20  Reality-TV              301086 non-null  bool   \n",
      " 21  Romance                 301086 non-null  bool   \n",
      " 22  Sci-Fi                  301086 non-null  bool   \n",
      " 23  Sport                   301086 non-null  bool   \n",
      " 24  Talk-Show               301086 non-null  bool   \n",
      " 25  Thriller                301086 non-null  bool   \n",
      " 26  War                     301086 non-null  bool   \n",
      " 27  Western                 301086 non-null  bool   \n",
      " 28  title_ratings_numVotes  301086 non-null  float64\n",
      " 29  title                   301086 non-null  object \n",
      " 30  tmdb_popularity         301086 non-null  float64\n",
      " 31  tmdb_US                 301086 non-null  bool   \n",
      " 32  tmdb_FR                 301086 non-null  bool   \n",
      " 33  tmdb_GB                 301086 non-null  bool   \n",
      " 34  tmdb_DE                 301086 non-null  bool   \n",
      " 35  tmdb_JP                 301086 non-null  bool   \n",
      " 36  tmdb_IN                 301086 non-null  bool   \n",
      " 37  tmdb_IT                 301086 non-null  bool   \n",
      " 38  tmdb_CA                 301086 non-null  bool   \n",
      " 39  tmdb_ES                 301086 non-null  bool   \n",
      " 40  tmdb_MX                 301086 non-null  bool   \n",
      " 41  tmdb_HK                 301086 non-null  bool   \n",
      " 42  tmdb_BR                 301086 non-null  bool   \n",
      " 43  tmdb_SE                 301086 non-null  bool   \n",
      " 44  tmdb_SU                 301086 non-null  bool   \n",
      " 45  tmdb_PH                 301086 non-null  bool   \n",
      " 46  tmdb_KR                 301086 non-null  bool   \n",
      " 47  tmdb_AU                 301086 non-null  bool   \n",
      " 48  tmdb_CN                 301086 non-null  bool   \n",
      " 49  tmdb_AR                 301086 non-null  bool   \n",
      " 50  tmdb_RU                 301086 non-null  bool   \n",
      " 51  tmdb_DK                 301086 non-null  bool   \n",
      " 52  tmdb_NL                 301086 non-null  bool   \n",
      " 53  tmdb_BE                 301086 non-null  bool   \n",
      " 54  tmdb_AT                 301086 non-null  bool   \n",
      " 55  tmdb_TR                 301086 non-null  bool   \n",
      " 56  tmdb_PL                 301086 non-null  bool   \n",
      " 57  tmdb_CH                 301086 non-null  bool   \n",
      " 58  tmdb_XC                 301086 non-null  bool   \n",
      " 59  tmdb_FI                 301086 non-null  bool   \n",
      " 60  tmdb_NO                 301086 non-null  bool   \n",
      " 61  tmdb_IR                 301086 non-null  bool   \n",
      " 62  tmdb_XG                 301086 non-null  bool   \n",
      " 63  tmdb_EG                 301086 non-null  bool   \n",
      " 64  tmdb_NG                 301086 non-null  bool   \n",
      " 65  tmdb_ZA                 301086 non-null  bool   \n",
      " 66  rating                  301086 non-null  float64\n",
      " 67  nconst                  301086 non-null  object \n",
      " 68  notes                   301086 non-null  float64\n",
      "dtypes: bool(60), float64(6), object(3)\n",
      "memory usage: 40.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut entrainer notre modèle sur tout le dataframe et afficher UNIQUEMENT les k films les plus proches dont les notes sont supérieures à 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation(tconst):\n",
    "\n",
    "     df_ml = pd.read_csv(\"../machine learning/DF_ML.csv.gz\")\n",
    "\n",
    "     index = df_ml.index\n",
    "     df_ml_num = df_ml.select_dtypes('number')\n",
    "     df_ml_cat = df_ml.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_ml_num_SN = pd.DataFrame(SN.fit_transform(df_ml_num), columns=df_ml_num.columns, index=index)\n",
    "\n",
    "     df_ml_encoded = pd.concat([df_ml_num_SN, df_ml_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_ml_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes','tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_ml_encoded[df_ml_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_ml_encoded[df_ml_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_ml_encoded[df_ml_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     if caract_film['notes'].values[0] > 0.7:\n",
    "          distances = distances[0][1:11]\n",
    "          indices = indices[0][1:11]\n",
    "          selection = bons_films.iloc[indices]['tconst']\n",
    "     else:\n",
    "          distances = distances[0][0:10]\n",
    "          indices = indices[0][0:10]\n",
    "          selection = bons_films.iloc[indices]['tconst']\n",
    "\n",
    "     return selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33189</th>\n",
       "      <td>tt0061122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>tt0024601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48197</th>\n",
       "      <td>tt0085334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>tt0036818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120028</th>\n",
       "      <td>tt0380229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59167</th>\n",
       "      <td>tt0104940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127292</th>\n",
       "      <td>tt0439664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55450</th>\n",
       "      <td>tt0097958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57969</th>\n",
       "      <td>tt0102629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60018</th>\n",
       "      <td>tt0106677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst\n",
       "33189   tt0061122\n",
       "7469    tt0024601\n",
       "48197   tt0085334\n",
       "15764   tt0036818\n",
       "120028  tt0380229\n",
       "59167   tt0104940\n",
       "127292  tt0439664\n",
       "55450   tt0097958\n",
       "57969   tt0102629\n",
       "60018   tt0106677"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = recommandation('tt0099785')\n",
    "pd.DataFrame(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "weights = X_encoded[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)\n",
    "weights *= 2\n",
    "X_weighted = pd.concat([weights, X_encoded.drop(columns = ['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western'])], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test ML avec TF_IDF (sans les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_8736\\3263337905.py:1: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tmdb = pd.read_csv(\"../gitignore/tmdb_full.csv\")\n"
     ]
    }
   ],
   "source": [
    "tmdb = pd.read_csv(\"../gitignore/tmdb_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb = tmdb[['imdb_id', 'genres', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(left=df_ml, right=tmdb, how='left', left_on='tconst', right_on='imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation2(tconst):\n",
    "\n",
    "     index = df_test.index\n",
    "     df_test_num = df_test.select_dtypes('number')\n",
    "     df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "     df_test_encoded = pd.concat([df_test_num_SN, df_test_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_test_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', \n",
    "                                                      'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_test_encoded[df_test_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     colonnes = ['tconst', 'genres', 'overview', 'nconst']  # Liste à étendre si besoin\n",
    "     selection = bons_films.iloc[indices[0]][colonnes]\n",
    "     df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "     #On crée un nouveau df à partir des données textuelles pour l'étudier avec TF-IDF\n",
    "     df_tfidf = df_selection.copy()\n",
    "     df_tfidf['texte'] = df_selection[colonnes].fillna('').agg(' '.join, axis=1)\n",
    "     df_tfidf = pd.DataFrame(df_tfidf['texte'], columns=['texte'])\n",
    "\n",
    "     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "     from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "     #Limite aux 100 mots les plus présents et supprime les mots contenus dans plus de 80% des lignes\n",
    "     vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, max_features=100)\n",
    "     df_tfidf = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "     vectorizer2 = TfidfVectorizer(stop_words='english', max_df=0.8, max_features=100)\n",
    "     df_tfidf2 = vectorizer.fit_transform(df_tfidf2['texte'])\n",
    "\n",
    "     #On calcule la distance entre chaque vecteur\n",
    "     similarite = cosine_similarity(df_tfidf)\n",
    "\n",
    "     #On crée une liste de tuple avec un index et le score de similarite par rapport au film cible (index 0 car première ligne)\n",
    "     film_index = df_selection.index[0]\n",
    "     similarity_scores = list(enumerate(similarite[film_index]))\n",
    "\n",
    "     #On trie le résultat par rapport aux scores et par ordre decroissant en ignorant la partie index (key permet de cibler uniquement le score)\n",
    "     similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "     similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "     return similar_movies\n",
    "\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt9261284',\n",
       " 'tt7254090',\n",
       " 'tt0290819',\n",
       " 'tt13091334',\n",
       " 'tt5314484',\n",
       " 'tt0772176',\n",
       " 'tt0405096',\n",
       " 'tt3948080',\n",
       " 'tt1655431']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection2 = recommandation2('tt0107688')\n",
    "selection2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test ML avec TF_IDF (avec les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation2(tconst):\n",
    "\n",
    "     index = df_test.index\n",
    "     df_test_num = df_test.select_dtypes('number')\n",
    "     df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "     df_test_encoded = pd.concat([df_test_num_SN, df_test_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_test_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', \n",
    "                                                      'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_test_encoded[df_test_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     colonnes = ['tconst', 'genres', 'overview', 'nconst']  # Liste à étendre si besoin\n",
    "     selection = bons_films.iloc[indices[0]][colonnes]\n",
    "     df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "     #On définit les poids pour chaque colonne textuelle\n",
    "     colonnes_poids = {\n",
    "        'tconst': 0,\n",
    "        'genres': 2,\n",
    "        'overview': 1,\n",
    "        'nconst': 5\n",
    "     }\n",
    "\n",
    "     #On crée une colonne 'texte' pondérée dynamiquement\n",
    "     df_tfidf = df_selection.copy()\n",
    "     df_tfidf['texte'] = df_selection.apply(\n",
    "     lambda ligne: ' '.join(\n",
    "          (str(ligne[col]) + ' ') * poids for col, poids in colonnes_poids.items()\n",
    "     ),\n",
    "     axis=1\n",
    "     )\n",
    "\n",
    "     #On crée le DataFrame final pour TF-IDF\n",
    "     df_tfidf = pd.DataFrame(df_tfidf['texte'], columns=['texte'])\n",
    "\n",
    "     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "     from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "     #Limite aux 100 mots les plus présents et supprime les mots contenus dans plus de 80% des lignes\n",
    "     vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, max_features=100)\n",
    "     df_tfidf = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "     #On calcule la distance entre chaque vecteur\n",
    "     similarite = cosine_similarity(df_tfidf)\n",
    "\n",
    "     #On crée une liste de tuple avec un index et le score de similarite par rapport au film cible (index 0 car première ligne)\n",
    "     film_index = df_selection.index[0]\n",
    "     similarity_scores = list(enumerate(similarite[film_index]))\n",
    "\n",
    "     #On trie le résultat par rapport aux scores et par ordre decroissant en ignorant la partie index (key permet de cibler uniquement le score)\n",
    "     similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "     similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "     return similar_movies\n",
    "\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt1664684',\n",
       " 'tt0345600',\n",
       " 'tt2234345',\n",
       " 'tt13091334',\n",
       " 'tt0405096',\n",
       " 'tt0772176',\n",
       " 'tt0290819',\n",
       " 'tt11053418',\n",
       " 'tt14538640']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection2 = recommandation2('tt0107688')\n",
    "selection2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire un test avec un vecteur texte + un vecteur nconst que l'on va combiner avec HSTACK avant de faire cosine_sismilarity.\n",
    "\n",
    "## Faire un test avec lemmarizing (garder les mots en 'binômes')."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
