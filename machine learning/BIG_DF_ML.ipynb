{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_episodes = \"../exploration/BIG_DF_ML.ipynb\"\n",
    "\n",
    "db01 = pd.read_csv(\"../gitignore/title_basics_traite.csv\")\n",
    "db02 = pd.read_csv(\"../gitignore/title_ratings_final.tsv\", sep=\"\\t\")\n",
    "db03 = pd.read_csv(\"../gitignore/title.akas_final.tsv\", sep=\"\\t\")\n",
    "db04 = pd.read_csv(\"../gitignore/tmdb_ml_final.csv\")\n",
    "db05 = pd.read_csv(\"../gitignore/data_bechdel.csv\")\n",
    "db07 = pd.read_csv(\"../gitignore/name.basics.tsv\", sep=\"\\t\") \n",
    "db08 = pd.read_csv(\"../gitignore/title.crew.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "dbmerge_1 = pd.merge(db01, db02, right_on='title_ratings_tconst', left_on='tconst', how='left') #Title Basics + Title Ratings\n",
    "dbmerge_2 = pd.merge(dbmerge_1, db03, left_on='tconst', right_on='titleId', how='left') # + Title Akas\n",
    "dbmerge_3 = pd.merge(dbmerge_2, db04, left_on='tconst', right_on='tmdb_imdb_id', how='left') # + TMDB Full\n",
    "dbmerge_4 = pd.merge(dbmerge_3, db05, left_on='tconst', right_on='imdbid', how='left') # + Bechdel\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db08, left_on='tconst', right_on='tconst', how='left') # + Title Crew\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db07, left_on='directors', right_on='nconst', how='left') # + Name Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML = dbmerge_4.drop(columns=[\n",
    "    'titleType',\n",
    "    'genres', \n",
    "    'decade', \n",
    "    'Adult',\n",
    "    'Short',\n",
    "    'movie',\n",
    "    'tmdb_Comedy',\n",
    "    'tmdb_Adventure',\n",
    "    'tmdb_Drama',\n",
    "    'tmdb_Crime',\n",
    "    'tmdb_Action',\n",
    "    'tmdb_Documentary',\n",
    "    'tmdb_Animation',\n",
    "    'tmdb_Mystery',\n",
    "    'tmdb_Horror',\n",
    "    'tmdb_Western',\n",
    "    'tmdb_Science Fiction',\n",
    "    'tmdb_Thriller',\n",
    "    'tmdb_Romance',\n",
    "    'tmdb_Fantasy',\n",
    "    'tmdb_Family',\n",
    "    'tmdb_History',\n",
    "    'tmdb_Music',\n",
    "    'tmdb_War', \n",
    "    'ordering',\n",
    "    'region',\n",
    "    'language',\n",
    "    'types',\n",
    "    'attributes',\n",
    "    'isOriginalTitle',\n",
    "    'birthYear',\n",
    "    'deathYear',\n",
    "    'primaryProfession',\n",
    "    'knownForTitles',\n",
    "    'directors',\n",
    "    'writers'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BIG_DF_ML3 = BIG_DF_ML.dropna(subset=['title_ratings_averageRating','tmdb_vote_average'],how='all')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def moyenne_ponderee(ligne):\n",
    "\n",
    "    # Si 'title_ratings_averageRating' est NaN, on ne prend que 'tmdb_vote_average', et vice versa\n",
    "\n",
    "    if pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        return ligne['tmdb_vote_average']  # Si title_ratings_averageRating est vide, prendre tmdb_vote_average\n",
    "\n",
    "    elif pd.isna(ligne['tmdb_vote_average']) and not pd.isna(ligne['title_ratings_averageRating']):\n",
    "        return ligne['title_ratings_averageRating']  # Si tmdb_vote_average est vide, prendre title_ratings_averageRating\n",
    "\n",
    "    elif not pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        # Si les deux colonnes ont des valeurs, calculer la moyenne pondérée\n",
    "        return (ligne['title_ratings_averageRating'] * ligne['title_ratings_numVotes'] + ligne['tmdb_vote_average'] * ligne['tmdb_vote_count']) / (ligne['title_ratings_numVotes'] + ligne['tmdb_vote_count'])  # Moyenne simple, à ajuster si besoin !\n",
    "    else:\n",
    "        return np.nan  # Si les deux sont NaN, retourner NaN\n",
    "\n",
    "\n",
    "BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML4 = BIG_DF_ML3.drop(['title_ratings_averageRating','tmdb_vote_average','title_ratings_tconst','titleId','tmdb_imdb_id','imdbid', 'primaryName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startyear(ligne):\n",
    "\n",
    "    # Si 'start year' est 0, il prend la valeur 'tmbd release date'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['startYear'] == 0)&(BIG_DF_ML4['tmdb_release_date'] != 0), 'startYear'] = BIG_DF_ML4['tmdb_release_date']\n",
    "\n",
    "startyear(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_date(ligne):\n",
    "\n",
    "    # Si 'tmdn release date' est 0, il prend la valeur 'start year'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_release_date'] == 0)&(BIG_DF_ML4['startYear'] != 0), 'tmdb_release_date'] = BIG_DF_ML4['startYear']\n",
    "\n",
    "release_date(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'runtimeMinutes' est 0, il prend la valeur 'tmdb_runtime'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['runtimeMinutes'] == 0)&(BIG_DF_ML4['tmdb_runtime'] != 0), 'runtimeMinutes'] = BIG_DF_ML4['tmdb_runtime']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'tmdb_runtime' est 0, il prend la valeur 'runtimeMinutes'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_runtime'] == 0)&(BIG_DF_ML4['runtimeMinutes'] != 0), 'tmdb_runtime'] = BIG_DF_ML4['runtimeMinutes']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "import numpy as np\n",
    "BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "BIG_DF_ML4[BIG_DF_ML4['runtimeMinutes']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML4.drop(columns =['tmdb_runtime','tmdb_release_date','tmdb_original_title','tmdb_title','tmdb_vote_count','tmdb_TV Movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['runtimeMinutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['startYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_21540\\61637864.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Pour notre ML, on remplace toutes les valeurs nulles des pays de production par False \n",
    "Remplacer = [\n",
    "    'tmdb_US', 'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "    'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE', 'tmdb_SU',\n",
    "    'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR', 'tmdb_RU', 'tmdb_DK',\n",
    "    'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR', 'tmdb_PL', 'tmdb_CH', 'tmdb_XC',\n",
    "    'tmdb_FI', 'tmdb_NO', 'tmdb_IR', 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'\n",
    "]\n",
    "BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['rating'] = BIG_DF_ML5['rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['title_ratings_numVotes'] = BIG_DF_ML5['title_ratings_numVotes'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['tmdb_popularity'] = BIG_DF_ML5['tmdb_popularity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['nconst'] = BIG_DF_ML5['nconst'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']] = BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Étape 3 : Combiner les TF-IDF avec les autres caractéristiques\\nfrom scipy.sparse import hstack\\n\\nfeatures_ml = BIG_DF_ML5.drop(columns=[\\'nconst\\'])  # Exclure temporairement \\'writers\\'\\ncombined_features = hstack([X_tfidf, features_ml])\\n\\n# Étape 4 : Entraîner le modèle NearestNeighbors\\nmodel = NearestNeighbors(n_neighbors=10, metric=\\'cosine\\')\\nmodel.fit(combined_features)\\n\\n# Étape 5 : Exemple de prédiction\\nfilm_index = X_encoded[X_encoded[\\'tconst\\'] == \\'tt1375666\\'].index[0]  # Trouver l\\'index du film recherché\\ndistances, indices = model.kneighbors(combined_features[film_index])\\n\\n# Afficher les résultats\\nprint(\"Films similaires :\")\\nprint(X_encoded.iloc[indices[0]][\\'title\\'])'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"# Étape 3 : Combiner les TF-IDF avec les autres caractéristiques\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "features_ml = BIG_DF_ML5.drop(columns=['nconst'])  # Exclure temporairement 'writers'\n",
    "combined_features = hstack([X_tfidf, features_ml])\n",
    "\n",
    "# Étape 4 : Entraîner le modèle NearestNeighbors\n",
    "model = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "model.fit(combined_features)\n",
    "\n",
    "# Étape 5 : Exemple de prédiction\n",
    "film_index = X_encoded[X_encoded['tconst'] == 'tt1375666'].index[0]  # Trouver l'index du film recherché\n",
    "distances, indices = model.kneighbors(combined_features[film_index])\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Films similaires :\")\n",
    "print(X_encoded.iloc[indices[0]]['title'])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = \"../machine learning/DF_ML.csv.gz\"\n",
    "BIG_DF_ML5.to_csv(export, sep=\",\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = BIG_DF_ML5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de ML avec cible sur les notes > 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 301086 entries, 0 to 688339\n",
      "Data columns (total 69 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   tconst                  301086 non-null  object \n",
      " 1   startYear               301086 non-null  float64\n",
      " 2   runtimeMinutes          301086 non-null  float64\n",
      " 3   Action                  301086 non-null  bool   \n",
      " 4   Adventure               301086 non-null  bool   \n",
      " 5   Animation               301086 non-null  bool   \n",
      " 6   Biography               301086 non-null  bool   \n",
      " 7   Comedy                  301086 non-null  bool   \n",
      " 8   Crime                   301086 non-null  bool   \n",
      " 9   Documentary             301086 non-null  bool   \n",
      " 10  Drama                   301086 non-null  bool   \n",
      " 11  Family                  301086 non-null  bool   \n",
      " 12  Fantasy                 301086 non-null  bool   \n",
      " 13  Game-Show               301086 non-null  bool   \n",
      " 14  History                 301086 non-null  bool   \n",
      " 15  Horror                  301086 non-null  bool   \n",
      " 16  Music                   301086 non-null  bool   \n",
      " 17  Musical                 301086 non-null  bool   \n",
      " 18  Mystery                 301086 non-null  bool   \n",
      " 19  News                    301086 non-null  bool   \n",
      " 20  Reality-TV              301086 non-null  bool   \n",
      " 21  Romance                 301086 non-null  bool   \n",
      " 22  Sci-Fi                  301086 non-null  bool   \n",
      " 23  Sport                   301086 non-null  bool   \n",
      " 24  Talk-Show               301086 non-null  bool   \n",
      " 25  Thriller                301086 non-null  bool   \n",
      " 26  War                     301086 non-null  bool   \n",
      " 27  Western                 301086 non-null  bool   \n",
      " 28  title_ratings_numVotes  301086 non-null  float64\n",
      " 29  title                   301086 non-null  object \n",
      " 30  tmdb_popularity         301086 non-null  float64\n",
      " 31  tmdb_US                 301086 non-null  bool   \n",
      " 32  tmdb_FR                 301086 non-null  bool   \n",
      " 33  tmdb_GB                 301086 non-null  bool   \n",
      " 34  tmdb_DE                 301086 non-null  bool   \n",
      " 35  tmdb_JP                 301086 non-null  bool   \n",
      " 36  tmdb_IN                 301086 non-null  bool   \n",
      " 37  tmdb_IT                 301086 non-null  bool   \n",
      " 38  tmdb_CA                 301086 non-null  bool   \n",
      " 39  tmdb_ES                 301086 non-null  bool   \n",
      " 40  tmdb_MX                 301086 non-null  bool   \n",
      " 41  tmdb_HK                 301086 non-null  bool   \n",
      " 42  tmdb_BR                 301086 non-null  bool   \n",
      " 43  tmdb_SE                 301086 non-null  bool   \n",
      " 44  tmdb_SU                 301086 non-null  bool   \n",
      " 45  tmdb_PH                 301086 non-null  bool   \n",
      " 46  tmdb_KR                 301086 non-null  bool   \n",
      " 47  tmdb_AU                 301086 non-null  bool   \n",
      " 48  tmdb_CN                 301086 non-null  bool   \n",
      " 49  tmdb_AR                 301086 non-null  bool   \n",
      " 50  tmdb_RU                 301086 non-null  bool   \n",
      " 51  tmdb_DK                 301086 non-null  bool   \n",
      " 52  tmdb_NL                 301086 non-null  bool   \n",
      " 53  tmdb_BE                 301086 non-null  bool   \n",
      " 54  tmdb_AT                 301086 non-null  bool   \n",
      " 55  tmdb_TR                 301086 non-null  bool   \n",
      " 56  tmdb_PL                 301086 non-null  bool   \n",
      " 57  tmdb_CH                 301086 non-null  bool   \n",
      " 58  tmdb_XC                 301086 non-null  bool   \n",
      " 59  tmdb_FI                 301086 non-null  bool   \n",
      " 60  tmdb_NO                 301086 non-null  bool   \n",
      " 61  tmdb_IR                 301086 non-null  bool   \n",
      " 62  tmdb_XG                 301086 non-null  bool   \n",
      " 63  tmdb_EG                 301086 non-null  bool   \n",
      " 64  tmdb_NG                 301086 non-null  bool   \n",
      " 65  tmdb_ZA                 301086 non-null  bool   \n",
      " 66  rating                  301086 non-null  float64\n",
      " 67  nconst                  301086 non-null  object \n",
      " 68  notes                   301086 non-null  float64\n",
      "dtypes: bool(60), float64(6), object(3)\n",
      "memory usage: 40.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut entrainer notre modèle sur tout le dataframe et afficher UNIQUEMENT les k films les plus proches dont les notes sont supérieures à 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation(tconst):\n",
    "\n",
    "     df_ml = pd.read_csv(\"../machine learning/DF_ML.csv\")\n",
    "\n",
    "     index = df_ml.index\n",
    "     df_ml_num = df_ml.select_dtypes('number')\n",
    "     df_ml_cat = df_ml.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_ml_num_SN = pd.DataFrame(SN.fit_transform(df_ml_num), columns=df_ml_num.columns, index=index)\n",
    "\n",
    "     df_ml_encoded = pd.concat([df_ml_num_SN, df_ml_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_ml_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes','tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_ml_encoded[df_ml_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_ml_encoded[df_ml_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_ml_encoded[df_ml_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     if caract_film['notes'].values[0] > 0.7:\n",
    "          distances = distances[0][1:]\n",
    "          indices = indices[0][1:]\n",
    "          selection = bons_films.iloc[indices]['tconst']\n",
    "     else:\n",
    "          selection = bons_films.iloc[indices[0]]['tconst']\n",
    "\n",
    "     return selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33189</th>\n",
       "      <td>tt0061122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>tt0024601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48197</th>\n",
       "      <td>tt0085334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>tt0036818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120028</th>\n",
       "      <td>tt0380229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59167</th>\n",
       "      <td>tt0104940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127292</th>\n",
       "      <td>tt0439664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55450</th>\n",
       "      <td>tt0097958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57969</th>\n",
       "      <td>tt0102629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst\n",
       "33189   tt0061122\n",
       "7469    tt0024601\n",
       "48197   tt0085334\n",
       "15764   tt0036818\n",
       "120028  tt0380229\n",
       "59167   tt0104940\n",
       "127292  tt0439664\n",
       "55450   tt0097958\n",
       "57969   tt0102629"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = recommandation('tt0099785')\n",
    "pd.DataFrame(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "weights = X_encoded[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)\n",
    "weights *= 2\n",
    "X_weighted = pd.concat([weights, X_encoded.drop(columns = ['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western'])], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMISATION DE K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def evaluate_k(X_encoded, k_range):\\n\\n    from sklearn.metrics import silhouette_score\\n    from sklearn.cluster import KMeans\\n    from sklearn.neighbors import NearestNeighbors\\n    import numpy as np\\n\\n    avg_distances = []\\n    silhouette_scores = []\\n\\n    for k in k_range:\\n        # Calcul des distances moyennes pour chaque k\\n        model = NearestNeighbors(n_neighbors=k)\\n        model.fit(X_encoded)\\n        distances, _ = model.kneighbors(X_encoded)\\n        avg_distances.append(np.mean(distances))\\n\\n        # Calcul du score de silhouette\\n        # Nous utilisons KMeans pour créer des clusters et évaluer la qualité\\n        kmeans = KMeans(n_clusters=k, random_state=42)\\n        clusters = kmeans.fit_predict(X_encoded)\\n        if k > 1:  # Le score de silhouette nécessite au moins 2 clusters\\n            silhouette_scores.append(silhouette_score(X_encoded, clusters))\\n        else:\\n            silhouette_scores.append(0)\\n\\n    return avg_distances, silhouette_scores'"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def evaluate_k(X_encoded, k_range):\n",
    "\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    import numpy as np\n",
    "\n",
    "    avg_distances = []\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        # Calcul des distances moyennes pour chaque k\n",
    "        model = NearestNeighbors(n_neighbors=k)\n",
    "        model.fit(X_encoded)\n",
    "        distances, _ = model.kneighbors(X_encoded)\n",
    "        avg_distances.append(np.mean(distances))\n",
    "\n",
    "        # Calcul du score de silhouette\n",
    "        # Nous utilisons KMeans pour créer des clusters et évaluer la qualité\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X_encoded)\n",
    "        if k > 1:  # Le score de silhouette nécessite au moins 2 clusters\n",
    "            silhouette_scores.append(silhouette_score(X_encoded, clusters))\n",
    "        else:\n",
    "            silhouette_scores.append(0)\n",
    "\n",
    "    return avg_distances, silhouette_scores\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\n# Définition de la plage de k à tester\\nk_range = range(2, 21)\\n\\n# Évaluation des différentes valeurs de k\\nX_input = X_encoded.drop(columns=['tconst', 'title', 'liste_titles'])\\navg_distances, silhouette_scores = evaluate_k(X_input, k_range)\\n\\n# Création d'une visualisation pour aider à choisir k\\nplt.figure(figsize=(12, 5))\\n\\n# Premier graphique : Distance moyenne aux voisins\\nplt.subplot(1, 2, 1)\\nplt.plot(k_range, avg_distances, 'bo-')\\nplt.xlabel('Nombre de voisins (k)')\\nplt.ylabel('Distance moyenne aux voisins')\\nplt.title('Distance moyenne en fonction de k')\\nplt.grid(True)\\n\\n# Second graphique : Score de silhouette\\nplt.subplot(1, 2, 2)\\nplt.plot(k_range, silhouette_scores, 'ro-')\\nplt.xlabel('Nombre de clusters (k)')\\nplt.ylabel('Score de silhouette')\\nplt.title('Score de silhouette en fonction de k')\\nplt.grid(True)\\n\\nplt.tight_layout()\\nplt.show()\""
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition de la plage de k à tester\n",
    "k_range = range(2, 21)\n",
    "\n",
    "# Évaluation des différentes valeurs de k\n",
    "X_input = X_encoded.drop(columns=['tconst', 'title', 'liste_titles'])\n",
    "avg_distances, silhouette_scores = evaluate_k(X_input, k_range)\n",
    "\n",
    "# Création d'une visualisation pour aider à choisir k\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Premier graphique : Distance moyenne aux voisins\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, avg_distances, 'bo-')\n",
    "plt.xlabel('Nombre de voisins (k)')\n",
    "plt.ylabel('Distance moyenne aux voisins')\n",
    "plt.title('Distance moyenne en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Second graphique : Score de silhouette\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'ro-')\n",
    "plt.xlabel('Nombre de clusters (k)')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Trouver k optimal\\nmeilleur_k = k_range[silhouette_scores.index(max(silhouette_scores))]\\nprint(f\"Le k optimal est : {meilleur_k}\")'"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Trouver k optimal\n",
    "meilleur_k = k_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"Le k optimal est : {meilleur_k}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
